import requests
import time
import re
import urllib
import io
import logging
import BeautifulSoup
import os
import sys
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException


# Needed directories
saved_html_files_location = "/Users/intothelight/nycdatascience/tmp/data_dump/scraper_html_files"
processed_files_location = "/Users/intothelight/nycdatascience/tmp/data_dump/scraper_data_files"
log_files_location = "/Users/intothelight/nycdatascience/tmp/data_dump/scraper_log_files"
app_name = "html_scraper"

# create needed directories
if not os.path.exists(log_files_location):
    os.makedirs(log_files_location)
    
if not os.path.exists(saved_html_files_location):
    os.makedirs(saved_html_files_location)

if not os.path.exists(processed_files_location):
    os.makedirs(processed_files_location)
    
# start logging
logfile = time.strftime("%Y-%m-%d")
full_logfilepath = "{}/{}__{}.log".format(log_files_location,logfile,app_name)
logging.basicConfig(filename=full_logfilepath, format="%(asctime)s - %(levelname)s: %(message)s", datefmt="%m/%d/%Y %I:%M:%S %p", level=logging.DEBUG)

logging.info("Begin logging")


def check_url(url):
    response_code = requests.head(url)
    logging.info("url:%s , status code:%s", url ,response_code.status_code)
    return response_code.status_code < 400

scanner_url = "http://urlquery.net/api/v2/post.php?url=https://www.va.gov"
scanner_primer_url = "http://urlquery.net/index.php"
scanner_report_url = "http://urlquery.net/report.php?id="
website_url = "https://www.va.gov"



# temporary
# filename = "{}__{}__{}".format(datetime.now(),website_url,scanner_report_url)
# filename = urllib.quote_plus(filename)
# full_filepath = "{}/{}.html".format(saved_html_files_location,filename)
# print("Test filename path:")
# print(full_filepath)



if check_url(scanner_primer_url):
    logging.info("Scanner is up")
else:
    logging.error("Scanner not available")
    sys.exit()
    
    
if check_url(website_url):
    logging.info("Target site is up")
else:
    logging.warn("Target site not available")    
    
#session = requests.session()
session = webdriver.PhantomJS(executable_path="/Users/intothelight/anaconda/pkgs/phantomjs-2.1.1-0/bin/phantomjs")
session.set_window_size(1439, 799)

session.get(scanner_primer_url)
url_box_id = "url"
url_btn_id = "url-submit"
url_text_box = session.find_element_by_id(url_box_id)
url_text_box.send_keys(website_url)
url_submit_btn = session.find_element_by_id(url_btn_id)
url_submit_btn.click()
html_ready_to_save = False
waiting = True
wait_time = 30
report_status_id = "status"
while waiting:

    time.sleep(wait_time)
    logging.info("Current browser url:%s", session.current_url)
    matchObj = re.search(r"report",session.current_url, re.M|re.I)
    if matchObj:
        logging.info("Report url was matched")
        try:
            cell = session.find_element_by_id(report_status_id)
            logging.info("Status element found in html")
            matchReportObj = re.search(r"Report complete",cell.text, re.M|re.I)
            if matchReportObj:
                logging.info("Report complete, matched")
                waiting = False
                html_ready_to_save = True
            
        except:
            logging.warn("Exception")
            logging.info("Current browser url:%s", session.current_url)
            
    else:
        logging.info("Report url not matched yet")       
         

if html_ready_to_save:
    filename = "{}__{}__{}".format(datetime.now(),website_url,session.current_url)
    filename = urllib.quote_plus(filename)
    full_filepath = "{}/{}.html".format(saved_html_files_location,filename)
    logging.info("Going to save html source code here:%s",full_filepath ) 
    html_file = io.open(full_filepath, "w", encoding="utf8")
    html_file.write(session.page_source)
    html_file.close()
         

    
#     try:
#         cell = WebDriverWait(session, wait_time).until(EC.presence_of_element_located(session.find_element_by_id("status")))
#         #cell = session.find_element_by_id("status")
#         print("Status Element found:")
#         print(cell.text)
#         print("Current browser url:")
#         print(session.current_url)
#         waiting = False
#     except :
#         print("Exception")  
#         print("Current browser url:")
#         print(session.current_url)  
        
        
#print(session.page_source)
session.quit()
logging.info("Quit session connection")


# Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.13) Gecko/20101203 Firefox/3.6.13
# method=submit&url=&useragent=Mozilla%2F5.0+(Windows%3B+U%3B+Windows+NT+6.1%3B+en-US%3B+rv%3A1.9.2.13)+Gecko%2F20101203+Firefox%2F3.6.13&referer=
# method=submit&url=sinoptik.ua&useragent=Mozilla%2F5.0+(Windows%3B+U%3B+Windows+NT+6.1%3B+en-US%3B+rv%3A1.9.2.13)+Gecko%2F20101203+Firefox%2F3.6.13&referer=

# http://urlquery.net/api/v2/post.php?url=
# http://urlquery.net/api/v2/post.php?url=sinoptik.ua

# if qued:
#         http://urlquery.net/queued.php?id=2441139906
# then:
#       http://urlquery.net/report.php?id=2441322494

# payload = {"url": website_url ,
#            "method": "submit" ,
#            "useragent": "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.13) Gecko/20101203 Firefox/3.6.13",
#            "referer": ""}
# print("Payload to send")
# print("text: ", payload)
# print("--------------------")
# print("doing session.get()")
# session.get(scanner_primer_url)
# print("doing session.post()")
# response = session.post(scanner_url,allow_redirects=True,data=payload)
# print("about to print response.history")
# print(response.history)
# print("--------------------")
# if response.history:
#     print("Request was redirected")
#     for resp in response.history:
#         print(resp.status_code, resp.url)
#         print("Final destination:")
#         print(response.status_code, response.url)
#     else:
#         print("Request was not redirected")
#         
# print("--------------------")
# print("About to print response.text")
# print(response.text) 
# 
# response_data = ""
# response_data = response.json()
# 
# print("About to print result of response.json")
# print(response_data)
# 
# print("response_data data type:")
# print(type(response_data))
# 
# print("scan status=", response_data["status"])
# print("scan queue_id=", response_data["queue_id"])
# 
# report_url  = "%s%s" % (scanner_report_url,response_data["queue_id"])
# print("--------------------")
# print("report url:", report_url)
# response = session.get(report_url)
# print("about to print response.text")
# print(response.text)

